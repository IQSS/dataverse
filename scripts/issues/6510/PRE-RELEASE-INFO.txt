We recently discovered a *potential* data integrity issue in
Dataverse databases.  One manifests itself as duplicate DataFile
objects created for the same uploaded file (https://github.com/IQSS/dataverse/issues/6522); the other as duplicate
DataTable (tabular metadata) objects linked to the same
DataFile (https://github.com/IQSS/dataverse/issues/6510). This issue impacted approximately .03% of datasets in Harvard's Dataverse.  

To see if any datasets in your installation have been impacted by this data integrity issue, we've provided a diagnostic script here:

https://github.com/IQSS/dataverse/raw/6510-repeated-ingests/scripts/issues/6510/check_datafiles_6522_6510.sh

The script relies on the PostgreSQL utility psql to access the
database. You will need to edit the credentials at the top of the script
to match your database configuration.

If neither of the two issues is present in your database, you will see
a message "... no duplicate DataFile objects in your database" and "no
tabular files affected by this issue in your database".

If either, or both kinds of duplicates are detected, the script will
provide further instructions. We will need you to send us the produced
output to support@dataverse.org and we will assist you in resolving the issues in your
database.
